{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b4746c8-abd3-473a-b050-2580a2be4e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis \n",
    "\n",
    "client = redis.Redis('host.docker.internal', 6379, 0)\n",
    "\n",
    "client.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e839f3a3-f827-4d85-b49e-d6fc3df00357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import io\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pcomp_utils.kafka_confluent_utils import KafkaProducerHandler, KafkaConsumerHandler\n",
    "from pcomp_utils.activation_functions import ACTIVATIONS, relu, softmax\n",
    "from pcomp_utils.redis_utils import RedisHandler\n",
    "from pcomp_utils.minio_utils import MinioClient\n",
    "from pcomp_utils.utils import batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "910fbab6-325f-4103-b1f1-c0a1dc385513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads started\n",
      "Aggregated\n",
      "Aggregated\n",
      "Aggregated\n",
      "Aggregated\n",
      "Aggregated\n",
      "Aggregated\n"
     ]
    }
   ],
   "source": [
    "# Kafka Configuration\n",
    "KAFKA_BROKER = 'kafka:9092'\n",
    "\n",
    "class Neuron(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_id, weights, bias, activation, is_final_layer):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.neuron_id = neuron_id\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation_func = ACTIVATIONS.get(activation, relu)\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "        self.producer = None\n",
    "\n",
    "    def fetch_input(self, batch_id, batch_size, columns_size):\n",
    "        key = f\"batch:initial_data:{batch_id}\" if self.layer_id == 'layer_0' else f\"batch:layer_{int(self.layer_id[-1]) - 1}_{batch_id}\"\n",
    "        # Poll Redis until the data is available.\n",
    "        while True:\n",
    "            data = np.frombuffer(self.redis_handler.get(key), dtype=np.float64).reshape(-1, int(columns_size))\n",
    "            #data = self.redis_handler.get_batch(key, int(batch_size), int(columns_size)) if self.layer_id == 'layer_0' else np.frombuffer(self.redis_handler.get(key)).reshape(-1, columns_size)\n",
    "            if data is not None:\n",
    "                return data\n",
    "            print(f\"⏳ Neuron {self.neuron_id} waiting for input data for key: {key}\")\n",
    "\n",
    "    def process_and_send(self, batch_id, batch_size, columns_size):\n",
    "        input_data = self.fetch_input(batch_id, batch_size, columns_size)\n",
    "        z = np.dot(input_data, self.weights) + self.bias\n",
    "        output = z if self.is_final_layer else self.activation_func(z)\n",
    "        self.redis_handler.set(f\"batch:n_{self.layer_id_num}_{self.neuron_id}_{batch_id}\", output, True, 1000)\n",
    "        msg = f\"{self.neuron_id}|{batch_id}|{batch_size}|{columns_size}\"\n",
    "        self.producer.send(f'layer-{self.layer_id_num}-complete', msg, self.layer_id_num)\n",
    "        #self.producer.send(f'requests-responses', 'www.neuron.example')\n",
    "\n",
    "    def run(self):\n",
    "        # Instantiate Kafka consumer and producer inside the thread.\n",
    "        consumer = KafkaConsumerHandler(f'layer-{self.layer_id_num}', KAFKA_BROKER, partition=self.neuron_id)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                layer, batch_id_str, batch_size, columns_size = message.split('|')\n",
    "                if layer == self.layer_id:\n",
    "                    batch_id = int(batch_id_str)\n",
    "                    self.executor.submit(self.process_and_send, batch_id, batch_size, columns_size)\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                consumer.commit()\n",
    "                consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "\n",
    "class LayerCoordinator(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_count, is_final_layer=False):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.neuron_count = neuron_count\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.completed_neurons = {}\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "        self.producer = None\n",
    "\n",
    "    def run(self):\n",
    "        consumer = KafkaConsumerHandler(f'layer-{self.layer_id_num}-complete', KAFKA_BROKER, self.layer_id_num)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                neuron_id, batch_id, batch_size, columns_size = message.split('|')\n",
    "                neuron_id = int(neuron_id)\n",
    "                batch_id = int(batch_id)\n",
    "                if batch_id not in self.completed_neurons:\n",
    "                    self.completed_neurons[batch_id] = set()\n",
    "                self.completed_neurons[batch_id].add(neuron_id)\n",
    "\n",
    "                if len(self.completed_neurons[batch_id]) == self.neuron_count:\n",
    "                    print(\"Aggregated\")\n",
    "                    batch_size = int(batch_size)\n",
    "                    columns_size = int(columns_size)\n",
    "                    self.executor.submit(self.aggregate_neuron_outputs, batch_id, batch_size, columns_size)\n",
    "                    del self.completed_neurons[batch_id]\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                consumer.commit()\n",
    "                consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    def aggregate_neuron_outputs(self, batch_id, batch_size, columns_size):\n",
    "        outputs = np.squeeze(np.stack([self.redis_handler.get_batch(f\"batch:n_{self.layer_id_num}_{neuron}_{batch_id}\", batch_size, 1) for neuron in range(self.neuron_count)], axis=1))\n",
    "        # Store the aggregated result in Redis.\n",
    "        self.redis_handler.set(f\"batch:{self.layer_id}_{batch_id}\", outputs, True, 1000)\n",
    "        if not self.is_final_layer:\n",
    "            self.activate_next_layer(batch_id, batch_size, columns_size)\n",
    "        else:\n",
    "            self.redis_handler.hset('predictions', batch_id, prediction)\n",
    "            self.redis_handler.delete(f\"batch:initial_data:{batch_id}\")\n",
    "\n",
    "    def activate_next_layer(self, batch_id, batch_size, columns_size):\n",
    "        next_layer = f'layer_{self.layer_id_num + 1}'\n",
    "        self.producer.send('activate-layer', f\"{next_layer}|{batch_id}|{batch_size}|{self.neuron_count}\", self.layer_id_num + 1)\n",
    "        #self.producer.send(f'requests-responses', 'www.layercoordinator.example')\n",
    "            \n",
    "\n",
    "class Layer(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_count):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_count = neuron_count\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.executor = ThreadPoolExecutor(max_workers=8)\n",
    "        self.producer = None\n",
    "\n",
    "    def activate_neurons(self, batch_id, batch_size, columns_size):\n",
    "        for neuron_id in range(self.neuron_count):\n",
    "            self.executor.submit(self.send_activation, neuron_id, batch_id, batch_size, columns_size)\n",
    "\n",
    "    def send_activation(self, neuron_id, batch_id, batch_size, columns_size):\n",
    "        self.producer.send(f'layer-{self.layer_id_num}', f\"{self.layer_id}|{batch_id}|{batch_size}|{columns_size}\", neuron_id)\n",
    "        #self.producer.send(f'requests-responses', 'www.layer.example')\n",
    "\n",
    "    def run(self):\n",
    "        consumer = KafkaConsumerHandler('activate-layer', KAFKA_BROKER, self.layer_id_num)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                layer, batch_id_str, batch_size, columns_size = message.split('|')\n",
    "                if layer == self.layer_id:\n",
    "                    batch_id = int(batch_id_str)\n",
    "                    self.activate_neurons(batch_id, batch_size, columns_size)\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                consumer.commit()\n",
    "                consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "def predict_data():\n",
    "    batch_size = 100\n",
    "    producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    file = MinioClient(\"host.docker.internal:9000\", \"admin\", \"admin123\").get_object(\"my-bucket\", \"mnist.csv\")\n",
    "    data = np.genfromtxt(io.StringIO(file.read().decode('utf-8')), delimiter=',', skip_header=1)\n",
    "    features = data[:, :-1][:300]\n",
    "    for idx, batch in enumerate(batch_generator(features, batch_size), start=0):\n",
    "        redis_handler.set(f\"batch:initial_data:{idx}\", batch, True, 1000)\n",
    "        producer.send('activate-layer', f\"layer_0|{idx}|{batch_size}|784\", 0)\n",
    "    producer.close()\n",
    "\n",
    "# Load network and dataset\n",
    "data = json.load(open(\"node_based_model.json\"))\n",
    "#df = pd.read_csv('data/mnist.csv').head(10)\n",
    "\n",
    "neurons = []\n",
    "layers = []\n",
    "coordinators = []\n",
    "\n",
    "for layer_name, layer_info in data.items():\n",
    "    neurons += [Neuron(layer_id=layer_name, neuron_id=i, weights=node['weights'], bias=node['biases'], activation=node['activation'], is_final_layer=(layer_name == list(data.keys())[-1])) for i, node in enumerate(layer_info['nodes'])]\n",
    "    layers.append(Layer(layer_id=layer_name, neuron_count=len(layer_info['nodes'])))\n",
    "    coordinators.append(LayerCoordinator(layer_id=layer_name, neuron_count=len(layer_info['nodes']), is_final_layer=(layer_name == list(data.keys())[-1])))\n",
    "\n",
    "# Start all threads\n",
    "for thread in neurons + layers + coordinators:\n",
    "    thread.start()\n",
    "\n",
    "print(\"Threads started\")\n",
    "\n",
    "predict_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c251e00-8b57-4bf1-a355-159ae61aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = MinioClient(\"host.docker.internal:9000\", \"admin\", \"admin123\").get_object(\"my-bucket\", \"mnist.csv\")\n",
    "# data = np.genfromtxt(io.StringIO(file.read().decode('utf-8')), delimiter=',', skip_header=1)\n",
    "# features = data[:, :-1]\n",
    "# labels = data[:, -1]\n",
    "\n",
    "# redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "# pipe = redis_handler.pipeline()\n",
    "# for idx, label in enumerate(labels):\n",
    "#     pipe.hset(\"images_label\", str(idx), int(label))\n",
    "\n",
    "# pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20867d3b-537e-4af5-9497-9bd1aaf9eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, batch in enumerate(batch_generator(features, 1000), start=0):\n",
    "#     redis_handler.set(f\"initial_data:{idx}\", batch, True, 1000)\n",
    "\n",
    "# batch = redis_handler.get_batch(\"initial_data:0\", 1000, 784)\n",
    "# print(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "adf53f5b-c571-475d-a1df-27a47a694f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data found in Redis for key: batch:n_1_10_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_11_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_12_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_13_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_14_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_15_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_16_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_17_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_18_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_19_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_20_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_21_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_22_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_23_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_24_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_25_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_26_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_27_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_28_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_29_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_30_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_31_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_32_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_33_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_34_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_35_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_36_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_37_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_38_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_39_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_40_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_41_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_42_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_43_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_44_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_45_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_46_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_47_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_48_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_49_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_50_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_51_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_52_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_53_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_54_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_55_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_56_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_57_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_58_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_59_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_60_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_61_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_62_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_63_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_64_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_65_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_66_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_67_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_68_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_69_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_70_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_71_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_72_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_73_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_74_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_75_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_76_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_77_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_78_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_79_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_80_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_81_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_82_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_83_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_84_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_85_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_86_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_87_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_88_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_89_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_90_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_91_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_92_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_93_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_94_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_95_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_96_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_97_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_98_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_99_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_100_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_101_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_102_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_103_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_104_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_105_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_106_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_107_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_108_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_109_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_110_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_111_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_112_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_113_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_114_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_115_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_116_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_117_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_118_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_119_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_120_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_121_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_122_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_123_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_124_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_125_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_126_0\n",
      "⚠️ No data found in Redis for key: batch:n_1_127_0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# out = redis_handler.get_batch(f\"batch:n_0_0_0\", 10, 1)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(out)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mredis_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch:n_1_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mneuron\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mneuron\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m redis_handler\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch:layer_1_0\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/_core/shape_base.py:448\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    446\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    450\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    451\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "# out = redis_handler.get_batch(f\"batch:n_0_0_0\", 10, 1)\n",
    "# print(out)\n",
    "batch_size = 100\n",
    "\n",
    "outputs = np.squeeze(np.stack([redis_handler.get_batch(f\"batch:n_0_{neuron}_0\", batch_size, 1) for neuron in range(128)], axis=1))\n",
    "print(outputs.shape)\n",
    "redis_handler.set(f\"batch:layer_0_0\", outputs)\n",
    "\n",
    "#redis_handler.get_batch(\"batch:layer_0_0\", 10, 784)\n",
    "\n",
    "#inputs = np.frombuffer(redis_handler.get(\"batch:layer_0_0\"))#.reshape(10,1)\n",
    "input_data = np.frombuffer(redis_handler.get(\"batch:layer_1_0\")).reshape(-1, 128)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "74388522-a4d5-4c31-ab19-8ddf95ce5c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "weights = None\n",
    "bias = None\n",
    "for layer_name, layer_info in data.items():\n",
    "    if layer_name == \"layer_1\":\n",
    "        weights = layer_info['nodes'][0]['weights']\n",
    "        bias = layer_info['nodes'][0]['biases']\n",
    "z = np.dot(input_data, weights) + bias\n",
    "output = ACTIVATIONS[\"relu\"](z)\n",
    "print(np.argmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c99f2359-2afd-4bc2-91fe-079361df5623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "input_data = np.frombuffer(redis_handler.get(f\"batch:initial_data:0\"), dtype=np.float64).reshape(-1, 784)\n",
    "print(input_data.shape)\n",
    "weights = None\n",
    "bias = None\n",
    "for layer_name, layer_info in data.items():\n",
    "    if layer_name == \"layer_0\":\n",
    "        weights = layer_info['nodes'][0]['weights']\n",
    "        bias = layer_info['nodes'][0]['biases']\n",
    "z = np.dot(input_data, weights) + bias\n",
    "output = ACTIVATIONS[\"relu\"](z)\n",
    "print(output.shape)\n",
    "\n",
    "redis_handler.set(\"batch:n_0_0_0\", output, True, 1000)\n",
    "inp = np.squeeze(redis_handler.get_batch(\"batch:n_0_0_0\", 100, 1))\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4ee0c6-d540-41e6-aa67-0ccb3b0a97c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "file = MinioClient(\"host.docker.internal:9000\", \"admin\", \"admin123\").get_object(\"my-bucket\", \"mnist.csv\")\n",
    "data = np.genfromtxt(io.StringIO(file.read().decode('utf-8')), delimiter=',', skip_header=1)\n",
    "features = data[:, :-1]\n",
    "labels = data[:, -1]\n",
    "pipe = redis_handler.pipeline()\n",
    "for idx, label in enumerate(labels):\n",
    "    pipe.hset(\"images_label\", str(idx), int(label))\n",
    "pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "99c7a70b-a80b-4c99-a40c-5524906ee8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800,)\n"
     ]
    }
   ],
   "source": [
    "pred = redis_handler.get(\"batch:layer_0_0\")#.reshape(100,1)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc625486-ff0e-449e-b9ee-562c5f6fa674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
