{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d92ebe-4df7-4681-8694-387ec8ba16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis \n",
    "\n",
    "client = redis.Redis('host.docker.internal', 6379, 0)\n",
    "\n",
    "client.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68f596b-e555-45b0-bce6-80001e581f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads started\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "#import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pcomp_utils.kafka_confluent_utils import KafkaProducerHandler, KafkaConsumerHandler\n",
    "from pcomp_utils.activation_functions import ACTIVATIONS, relu, softmax\n",
    "from pcomp_utils.redis_utils import RedisHandler\n",
    "\n",
    "# Kafka Configuration\n",
    "KAFKA_BROKER = 'kafka:9092'\n",
    "\n",
    "class Neuron(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_id, weights, bias, activation, is_final_layer):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.neuron_id = neuron_id\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation_func = ACTIVATIONS.get(activation, relu)\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "        self.consumer = None\n",
    "        self.producer = None\n",
    "\n",
    "    def fetch_input(self, image_id):\n",
    "        key = f\"initial_data:{image_id}\" if self.layer_id == 'layer_0' else f\"layer_{int(self.layer_id[-1]) - 1}_{image_id}\"\n",
    "        # Poll Redis until the data is available.\n",
    "        while True:\n",
    "            data = self.redis_handler.get(key)\n",
    "            if data is not None:\n",
    "                return data\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    def process_data(self, inputs):\n",
    "        z = np.dot(inputs, self.weights) + self.bias\n",
    "        return z if self.is_final_layer else self.activation_func(z)\n",
    "\n",
    "    def process_and_send(self, image_id, input_data):\n",
    "        output = self.process_data(input_data)\n",
    "        msg = {\n",
    "            'neuron_id': self.neuron_id,\n",
    "            'image_id': image_id,\n",
    "            'output': output.astype(np.float64).tobytes().hex()\n",
    "        }\n",
    "        self.producer.send(f'layer-{self.layer_id_num}-complete', msg, self.layer_id_num)\n",
    "\n",
    "    def run(self):\n",
    "        # Instantiate Kafka consumer and producer inside the thread.\n",
    "        self.consumer = KafkaConsumerHandler(f'layer-{self.layer_id_num}', KAFKA_BROKER, partition=self.neuron_id)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in self.consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                if message.get('layer') == self.layer_id:\n",
    "                    image_id = message.get('image_id')\n",
    "                    input_data = self.fetch_input(image_id)\n",
    "                    if input_data is not None:\n",
    "                        self.executor.submit(self.process_and_send, image_id, input_data)\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                self.consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "\n",
    "\n",
    "class LayerCoordinator(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_count, is_final_layer=False):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.neuron_count = neuron_count\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.completed_neurons = {}\n",
    "        self.outputs = {}\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "        self.consumer = None\n",
    "        self.producer = None\n",
    "\n",
    "    def run(self):\n",
    "        self.consumer = KafkaConsumerHandler(f'layer-{self.layer_id_num}-complete', KAFKA_BROKER, self.layer_id_num)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in self.consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                image_id = message.get('image_id')\n",
    "                neuron_id = message.get('neuron_id')\n",
    "                output_hex = message.get('output')\n",
    "                output = np.frombuffer(bytes.fromhex(output_hex), dtype=np.float64)[0]\n",
    "                if image_id not in self.completed_neurons:\n",
    "                    self.completed_neurons[image_id] = set()\n",
    "                    self.outputs[image_id] = {}\n",
    "                self.completed_neurons[image_id].add(neuron_id)\n",
    "                self.outputs[image_id][neuron_id] = output\n",
    "\n",
    "                if len(self.completed_neurons[image_id]) == self.neuron_count:\n",
    "                    local_outputs = self.outputs[image_id].copy()\n",
    "                    self.executor.submit(self.aggregate_neuron_outputs, image_id, local_outputs)\n",
    "                    del self.completed_neurons[image_id]\n",
    "                    del self.outputs[image_id]\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                self.consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    def aggregate_neuron_outputs(self, image_id, local_outputs):\n",
    "        if not self.is_final_layer:\n",
    "            self.activate_next_layer(image_id)\n",
    "        outputs = np.array([local_outputs.get(neuron_id) for neuron_id in range(self.neuron_count)])\n",
    "        # Store the aggregated result in Redis.\n",
    "        self.redis_handler.set(f\"{self.layer_id}_{image_id}\", outputs)\n",
    "        if self.is_final_layer:\n",
    "            prediction = int(np.argmax(outputs))\n",
    "            self.redis_handler.hset('predictions', image_id, prediction)\n",
    "            self.redis_handler.delete(f\"initial_data:{image_id}\")\n",
    "\n",
    "    def activate_next_layer(self, image_id):\n",
    "        next_layer = f'layer_{self.layer_id_num + 1}'\n",
    "        self.producer.send('activate-layer', {'layer': next_layer, 'image_id': image_id}, self.layer_id_num + 1)\n",
    "            \n",
    "\n",
    "class Layer(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_count):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_count = neuron_count\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.executor = ThreadPoolExecutor(max_workers=8)\n",
    "        self.consumer = None\n",
    "        self.producer = None\n",
    "\n",
    "    def activate_neurons(self, image_id):\n",
    "        for neuron_id in range(self.neuron_count):\n",
    "            self.executor.submit(self.send_activation, neuron_id, image_id)\n",
    "\n",
    "    def send_activation(self, neuron_id, image_id):\n",
    "        self.producer.send(f'layer-{self.layer_id_num}', {'layer': self.layer_id, 'image_id': image_id}, neuron_id)\n",
    "\n",
    "    def run(self):\n",
    "        self.consumer = KafkaConsumerHandler('activate-layer', KAFKA_BROKER, self.layer_id_num)\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in self.consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                if message.get('layer') == self.layer_id:\n",
    "                    image_id = message.get('image_id')\n",
    "                    self.activate_neurons(image_id)\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                self.consumer.close()\n",
    "                self.producer.close()\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def store_initial_input_data(image_np, image_id):\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    key = f\"initial_data:{image_id}\"\n",
    "    redis_handler.set(key, image_np)\n",
    "    print(f\"ðŸ“¥ Initial input data stored in Redis.\")\n",
    "\n",
    "def activate_network(image_id):\n",
    "    producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "    producer.send('activate-layer', {'layer': 'layer_0', 'image_id': image_id}, 0)\n",
    "    print(f\"ðŸš€ Initial activation sent to activate-layer for layer_0 and image {image_id}\")\n",
    "    producer.close()\n",
    "\n",
    "# Load network and dataset\n",
    "data = json.load(open(\"node_based_model.json\"))\n",
    "#df = pd.read_csv('data/mnist.csv').head(10)\n",
    "\n",
    "neurons = []\n",
    "layers = []\n",
    "coordinators = []\n",
    "\n",
    "for layer_name, layer_info in data.items():\n",
    "    neurons += [Neuron(layer_id=layer_name, neuron_id=i, weights=node['weights'], bias=node['biases'], activation=node['activation'], is_final_layer=(layer_name == list(data.keys())[-1])) for i, node in enumerate(layer_info['nodes'])]\n",
    "    layers.append(Layer(layer_id=layer_name, neuron_count=len(layer_info['nodes'])))\n",
    "    coordinators.append(LayerCoordinator(layer_id=layer_name, neuron_count=len(layer_info['nodes']), is_final_layer=(layer_name == list(data.keys())[-1])))\n",
    "\n",
    "# Start all threads\n",
    "for thread in neurons + layers + coordinators:\n",
    "    thread.start()\n",
    "\n",
    "print(\"Threads started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde9b593-bd3e-412d-8952-55a50b83dbf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Wait for all threads to complete\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m neurons \u001b[38;5;241m+\u001b[39m coordinators:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreads finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Wait for all threads to complete\n",
    "for thread in neurons + coordinators:\n",
    "    thread.join()\n",
    "\n",
    "print(\"Threads finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d722f-4bb6-4f2e-9864-8003a6a1f9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
