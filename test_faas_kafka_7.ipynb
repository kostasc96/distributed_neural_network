{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a2c16-d57e-40e7-bd18-06742f0ef367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "#from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from pcomp_utils.kafka_producer_utils import KafkaProducerHandler\n",
    "from pcomp_utils.kafka_consumer_utils import KafkaConsumerHandler\n",
    "from pcomp_utils.activation_functions import ACTIVATIONS, relu, softmax\n",
    "from pcomp_utils.redis_utils import RedisHandler\n",
    "\n",
    "# Kafka Configuration\n",
    "KAFKA_BROKER = 'kafka:9092'\n",
    "\n",
    "\n",
    "class Neuron(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_id, weights, bias, activation, is_final_layer=False):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_id = neuron_id\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation_func = None if is_final_layer else ACTIVATIONS.get(activation, relu)\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.output = None\n",
    "        self.consumer = KafkaConsumerHandler(f'layer-{self.layer_id[-1]}', KAFKA_BROKER, partition=self.neuron_id)\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "    def fetch_input(self):\n",
    "        return self.redis_handler.get(\"initial_data\") if self.layer_id == 'layer_0' else self.redis_handler.get(f'layer_{int(self.layer_id[-1]) - 1}')\n",
    "\n",
    "    def process_data(self, inputs):\n",
    "        z = np.dot(inputs, self.weights) + self.bias\n",
    "        return z if self.is_final_layer else self.activation_func(z)\n",
    "\n",
    "    def run(self):\n",
    "        for message in self.consumer.consume():\n",
    "            if message.value.get('layer') == self.layer_id:\n",
    "                input_data = self.fetch_input()\n",
    "                self.output = self.process_data(input_data)\n",
    "                print(f\"‚úÖ Neuron {self.neuron_id} in {self.layer_id} processed data.\")\n",
    "                break\n",
    "        self.consumer.close()\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, layer_id, neuron_configs, is_final_layer=False):\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_configs = neuron_configs\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.neurons = []\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "    def initialize_neurons(self):\n",
    "        self.neurons = [\n",
    "            Neuron(\n",
    "                layer_id=self.layer_id,\n",
    "                neuron_id=idx,\n",
    "                weights=neuron['weights'],\n",
    "                bias=neuron['biases'],\n",
    "                activation=neuron['activation'],\n",
    "                is_final_layer=self.is_final_layer\n",
    "            )\n",
    "            for idx, neuron in enumerate(self.neuron_configs)\n",
    "        ]\n",
    "\n",
    "    def forward(self, image_id):\n",
    "        self.initialize_neurons()\n",
    "\n",
    "        # Start neuron threads\n",
    "        for neuron in self.neurons:\n",
    "            neuron.start()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Send activation message to each neuron's partition\n",
    "        producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "\n",
    "        for neuron_id in range(len(self.neurons)):\n",
    "            activation_message = {'layer': self.layer_id}\n",
    "            producer.send(f'layer-{self.layer_id[-1]}', activation_message, neuron_id)\n",
    "            #print(f\"‚úÖ Layer {self.layer_id} sent activation to Neuron {neuron_id} on partition {neuron_id}\")\n",
    "\n",
    "        producer.close()\n",
    "\n",
    "        # Wait for all neuron threads to complete\n",
    "        for neuron in self.neurons:\n",
    "            neuron.join()\n",
    "\n",
    "        # Aggregate and store neuron outputs\n",
    "        outputs = np.array([neuron.output for neuron in self.neurons])\n",
    "        self.redis_handler.set(self.layer_id, outputs)\n",
    "        print(f\"üìù Layer {self.layer_id} stored aggregated data in Redis.\")\n",
    "\n",
    "        if self.is_final_layer:\n",
    "            prediction = int(np.argmax(outputs))\n",
    "            self.redis_handler.hset('predictions', image_id, prediction)\n",
    "            print(f\"üéØ Prediction for Image {image_id}: {prediction}\")\n",
    "\n",
    "        if not self.is_final_layer:\n",
    "            self.activate_next_layer()\n",
    "\n",
    "    def activate_next_layer(self):\n",
    "        producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        next_layer = f'layer_{int(self.layer_id[-1]) + 1}'\n",
    "        print(f\"üöÄ Activating next layer: {next_layer}\")\n",
    "        producer.send('activate-layer', {'layer': next_layer})\n",
    "        producer.close()\n",
    "\n",
    "\n",
    "\n",
    "def store_initial_input_data(input_data):\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    redis_handler.set(\"initial_data\", input_data)\n",
    "    print(\"üì• Initial input data stored in Redis under 'initial_data' key.\")\n",
    "\n",
    "def calculate_accuracy(file_path, limit=10):\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    df = pd.read_csv(file_path).head(limit)\n",
    "    predictions = redis_handler.hgetall('predictions')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        label = int(row['label'])\n",
    "        prediction = predictions.get(str(idx).encode())  # Decode Redis key lookup\n",
    "\n",
    "        if prediction is not None:\n",
    "            prediction = int(prediction.decode())  # Decode the Redis stored value\n",
    "            print(f\"‚úÖ Prediction for Image {idx}: {prediction}, Actual Label: {label}\")\n",
    "\n",
    "            if prediction == label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No prediction found for Image ID: {idx}\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"‚ö†Ô∏è No valid predictions to calculate accuracy.\")\n",
    "        return\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"üéØ Test Accuracy (First {limit} Images): {accuracy * 100:.2f}%\")\n",
    "\n",
    "def load_network(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_network(json_data):\n",
    "    layers = []\n",
    "    sorted_layers = sorted(json_data.keys(), key=lambda x: int(x.split('_')[-1]))\n",
    "    for i, layer_name in enumerate(sorted_layers):\n",
    "        layer_info = json_data[layer_name]\n",
    "        neuron_configs = layer_info['nodes']\n",
    "        layers.append(Layer(layer_id=layer_name, neuron_configs=neuron_configs, is_final_layer=(i == len(sorted_layers) - 1)))\n",
    "    return layers\n",
    "\n",
    "def forward_pass(layers, image_np, image_id):\n",
    "    store_initial_input_data(image_np)\n",
    "    for layer in layers:\n",
    "        layer.forward(image_id)\n",
    "\n",
    "# Load network\n",
    "data = load_network(\"node_based_model.json\")\n",
    "network = build_network(data)\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/mnist.csv').head(10)  # Only the first 10 images\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_np = row.iloc[:-1].values.astype(np.float32)  # Extract image pixels\n",
    "    label = row.iloc[-1]  # Extract label\n",
    "    forward_pass(network, image_np, idx)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "calculate_accuracy('data/mnist.csv', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
