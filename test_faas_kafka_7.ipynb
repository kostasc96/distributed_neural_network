{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683a2c16-d57e-40e7-bd18-06742f0ef367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Initial input data stored in Redis under 'initial_data' key.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 174\u001b[0m\n\u001b[1;32m    172\u001b[0m     image_np \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)  \u001b[38;5;66;03m# Extract image pixels\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     label \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Extract label\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Calculate and print accuracy\u001b[39;00m\n\u001b[1;32m    177\u001b[0m calculate_accuracy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/mnist.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 162\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(layers, image_np, image_id)\u001b[0m\n\u001b[1;32m    160\u001b[0m store_initial_input_data(image_np)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 66\u001b[0m, in \u001b[0;36mLayer.forward\u001b[0;34m(self, image_id)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_id):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_neurons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Start neuron threads\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons:\n",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m, in \u001b[0;36mLayer.initialize_neurons\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minitialize_neurons\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     54\u001b[0m         Neuron(\n\u001b[1;32m     55\u001b[0m             layer_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_id,\n\u001b[1;32m     56\u001b[0m             neuron_id\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m     57\u001b[0m             weights\u001b[38;5;241m=\u001b[39mneuron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     58\u001b[0m             bias\u001b[38;5;241m=\u001b[39mneuron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiases\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     59\u001b[0m             activation\u001b[38;5;241m=\u001b[39mneuron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     60\u001b[0m             is_final_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_final_layer\n\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneuron_configs)\n\u001b[1;32m     63\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minitialize_neurons\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 54\u001b[0m         \u001b[43mNeuron\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneuron_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbiases\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_final_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_final_layer\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneuron_configs)\n\u001b[1;32m     63\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m, in \u001b[0;36mNeuron.__init__\u001b[0;34m(self, layer_id, neuron_id, weights, bias, activation, is_final_layer)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_final_layer \u001b[38;5;241m=\u001b[39m is_final_layer\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsumer \u001b[38;5;241m=\u001b[39m \u001b[43mKafkaConsumerHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_id\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKAFKA_BROKER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredis_handler \u001b[38;5;241m=\u001b[39m RedisHandler(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost.docker.internal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m6379\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/app/pcomp_utils/kafka_consumer_utils.py:6\u001b[0m, in \u001b[0;36mKafkaConsumerHandler.__init__\u001b[0;34m(self, topic, servers, partition)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, topic, servers, partition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsumer \u001b[38;5;241m=\u001b[39m \u001b[43mKafkaConsumer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbootstrap_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_deserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_offset_reset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_auto_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsumer_timeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60000\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         tp \u001b[38;5;241m=\u001b[39m TopicPartition(topic, partition)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/kafka/consumer/group.py:358\u001b[0m, in \u001b[0;36mKafkaConsumer.__init__\u001b[0;34m(self, *topics, **configs)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, str_version\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    355\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse api_version=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [tuple] -- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as str is deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    356\u001b[0m                 \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m]), str_version)\n\u001b[0;32m--> 358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkafka_client\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/kafka/client_async.py:240\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Check Broker Version if not set explicitly\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/kafka/client_async.py:960\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     remaining \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 960\u001b[0m     version \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbootstrap_topics_filter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;66;03m# cache the api versions map if it's available (starting\u001b[39;00m\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# in 0.10 cluster version)\u001b[39;00m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_versions \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mget_api_versions()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/kafka/conn.py:1257\u001b[0m, in \u001b[0;36mBrokerConnection.check_version\u001b[0;34m(self, timeout, strict, topics)\u001b[0m\n\u001b[1;32m   1255\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;66;03m# HACK: sleeping to wait for socket to send bytes\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# when broker receives an unrecognized request API\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;66;03m# it abruptly closes our socket.\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;66;03m# so we attempt to send a second request immediately\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;66;03m# immediately fail and allow us to infer that the prior\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;66;03m# request was unrecognized\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m mr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(MetadataRequest[\u001b[38;5;241m0\u001b[39m](topics))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import pandas as pd\n",
    "from pcomp_utils.kafka_producer_utils import KafkaProducerHandler\n",
    "from pcomp_utils.kafka_consumer_utils import KafkaConsumerHandler\n",
    "from pcomp_utils.activation_functions import ACTIVATIONS, relu, softmax\n",
    "from pcomp_utils.redis_utils import RedisHandler\n",
    "\n",
    "# Kafka Configuration\n",
    "KAFKA_BROKER = 'kafka:9092'\n",
    "\n",
    "\n",
    "class Neuron(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_id, weights, bias, activation, is_final_layer=False):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_id = neuron_id\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation_func = None if is_final_layer else ACTIVATIONS.get(activation, relu)\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.output = None\n",
    "        self.consumer = KafkaConsumerHandler(f'layer-{self.layer_id[-1]}', KAFKA_BROKER, partition=self.neuron_id)\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "    def fetch_input(self):\n",
    "        return self.redis_handler.get(\"initial_data\") if self.layer_id == 'layer_0' else self.redis_handler.get(f'layer_{int(self.layer_id[-1]) - 1}')\n",
    "\n",
    "    def process_data(self, inputs):\n",
    "        z = np.dot(inputs, self.weights) + self.bias\n",
    "        return z if self.is_final_layer else self.activation_func(z)\n",
    "\n",
    "    def run(self):\n",
    "        for message in self.consumer.consume():\n",
    "            if message.value.get('layer') == self.layer_id:\n",
    "                input_data = self.fetch_input()\n",
    "                self.output = self.process_data(input_data)\n",
    "                print(f\"✅ Neuron {self.neuron_id} in {self.layer_id} processed data.\")\n",
    "                break\n",
    "        self.consumer.close()\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, layer_id, neuron_configs, is_final_layer=False):\n",
    "        self.layer_id = layer_id\n",
    "        self.neuron_configs = neuron_configs\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.neurons = []\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "    def initialize_neurons(self):\n",
    "        self.neurons = [\n",
    "            Neuron(\n",
    "                layer_id=self.layer_id,\n",
    "                neuron_id=idx,\n",
    "                weights=neuron['weights'],\n",
    "                bias=neuron['biases'],\n",
    "                activation=neuron['activation'],\n",
    "                is_final_layer=self.is_final_layer\n",
    "            )\n",
    "            for idx, neuron in enumerate(self.neuron_configs)\n",
    "        ]\n",
    "\n",
    "    def forward(self, image_id):\n",
    "        self.initialize_neurons()\n",
    "\n",
    "        # Start neuron threads\n",
    "        for neuron in self.neurons:\n",
    "            neuron.start()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Send activation message to each neuron's partition\n",
    "        producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "\n",
    "        for neuron_id in range(len(self.neurons)):\n",
    "            activation_message = {'layer': self.layer_id}\n",
    "            producer.send(f'layer-{self.layer_id[-1]}', activation_message, neuron_id)\n",
    "            #print(f\"✅ Layer {self.layer_id} sent activation to Neuron {neuron_id} on partition {neuron_id}\")\n",
    "\n",
    "        producer.close()\n",
    "\n",
    "        # Wait for all neuron threads to complete\n",
    "        for neuron in self.neurons:\n",
    "            neuron.join()\n",
    "\n",
    "        # Aggregate and store neuron outputs\n",
    "        outputs = np.array([neuron.output for neuron in self.neurons])\n",
    "        print(\"Outputs:\")\n",
    "        print(outputs)\n",
    "        self.redis_handler.set(self.layer_id, outputs)\n",
    "        print(f\"📝 Layer {self.layer_id} stored aggregated data in Redis.\")\n",
    "\n",
    "        if self.is_final_layer:\n",
    "            prediction = int(np.argmax(outputs))\n",
    "            self.redis_handler.hset('predictions', image_id, prediction)\n",
    "            print(f\"🎯 Prediction for Image {image_id}: {prediction}\")\n",
    "\n",
    "        if not self.is_final_layer:\n",
    "            self.activate_next_layer()\n",
    "\n",
    "    def activate_next_layer(self):\n",
    "        producer = KafkaProducerHandler(KAFKA_BROKER)\n",
    "        next_layer = f'layer_{int(self.layer_id[-1]) + 1}'\n",
    "        print(f\"🚀 Activating next layer: {next_layer}\")\n",
    "        producer.send('activate-layer', {'layer': next_layer})\n",
    "        producer.close()\n",
    "\n",
    "\n",
    "\n",
    "def store_initial_input_data(input_data):\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    redis_handler.set(\"initial_data\", input_data)\n",
    "    print(\"📥 Initial input data stored in Redis under 'initial_data' key.\")\n",
    "\n",
    "def calculate_accuracy(file_path, limit=10):\n",
    "    redis_handler = RedisHandler('host.docker.internal', 6379, 0)\n",
    "    df = pd.read_csv(file_path).head(limit)\n",
    "    predictions = redis_handler.hgetall('predictions')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        label = int(row['label'])\n",
    "        prediction = predictions.get(str(idx).encode())  # Decode Redis key lookup\n",
    "\n",
    "        if prediction is not None:\n",
    "            prediction = int(prediction.decode())  # Decode the Redis stored value\n",
    "            print(f\"✅ Prediction for Image {idx}: {prediction}, Actual Label: {label}\")\n",
    "\n",
    "            if prediction == label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        else:\n",
    "            print(f\"⚠️ No prediction found for Image ID: {idx}\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"⚠️ No valid predictions to calculate accuracy.\")\n",
    "        return\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"🎯 Test Accuracy (First {limit} Images): {accuracy * 100:.2f}%\")\n",
    "\n",
    "def load_network(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_network(json_data):\n",
    "    layers = []\n",
    "    sorted_layers = sorted(json_data.keys(), key=lambda x: int(x.split('_')[-1]))\n",
    "    for i, layer_name in enumerate(sorted_layers):\n",
    "        layer_info = json_data[layer_name]\n",
    "        neuron_configs = layer_info['nodes']\n",
    "        layers.append(Layer(layer_id=layer_name, neuron_configs=neuron_configs, is_final_layer=(i == len(sorted_layers) - 1)))\n",
    "    return layers\n",
    "\n",
    "def forward_pass(layers, image_np, image_id):\n",
    "    store_initial_input_data(image_np)\n",
    "    for layer in layers:\n",
    "        layer.forward(image_id)\n",
    "\n",
    "# Load network\n",
    "data = load_network(\"node_based_model.json\")\n",
    "network = build_network(data)\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/mnist.csv').head(2)  # Only the first 10 images\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_np = row.iloc[:-1].values.astype(np.float64)  # Extract image pixels\n",
    "    label = row.iloc[-1]  # Extract label\n",
    "    forward_pass(network, image_np, idx)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "calculate_accuracy('data/mnist.csv', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f687308-fad4-46e7-82b1-ce3c445eec4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
