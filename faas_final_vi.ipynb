{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "700567b6-acb1-4ad7-89e6-6c3a0dfed2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis \n",
    "\n",
    "client = redis.Redis('host.docker.internal', 6379, 0)\n",
    "\n",
    "client.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "815aa9ef-1d9b-40f6-b4bf-afd5af068c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pcomp.kafka_handlers import KafkaProducerHandler, KafkaConsumerHandler, KafkaConsumerHandlerNeuron\n",
    "from pcomp.activation_functions import ACTIVATIONS, relu, softmax\n",
    "from pcomp.redis_utils import RedisHandler\n",
    "from pcomp.parser import parse_layer_coordinator_message, parse_layer_message\n",
    "from pcomp.avro_utils import avro_serialize, avro_deserialize\n",
    "from pcomp.neurons_accumulator import NeuronsAccumulator\n",
    "\n",
    "# Kafka Configuration\n",
    "KAFKA_BROKER = 'kafka:29092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f0678e9-26bb-41d9-ace6-cfd6ea863ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1744241922.106|OFFSET|rdkafka#consumer-1662| [thrd:main]: layer-output [0]: offset reset (at offset 68 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.735|OFFSET|rdkafka#consumer-1642| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.737|OFFSET|rdkafka#consumer-1643| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.739|OFFSET|rdkafka#consumer-1647| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.741|OFFSET|rdkafka#consumer-1652| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.741|OFFSET|rdkafka#consumer-1649| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.742|OFFSET|rdkafka#consumer-1653| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.840|OFFSET|rdkafka#consumer-1645| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.844|OFFSET|rdkafka#consumer-1655| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.848|OFFSET|rdkafka#consumer-1658| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n",
      "%4|1744241923.849|OFFSET|rdkafka#consumer-1659| [thrd:main]: layer-1 [6]: offset reset (at offset 2 (leader epoch 0), broker 1) to offset END (leader epoch -1): fetch failed due to requested offset not available on the broker: Broker: Offset out of range\n"
     ]
    }
   ],
   "source": [
    "class Neuron(threading.Thread):\n",
    "    def __init__(self, layer_id, neuron_id, weights, bias, activation, is_final_layer):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.layer_id = layer_id\n",
    "        self.layer_id_num = int(self.layer_id.replace(\"layer_\", \"\"))\n",
    "        self.neuron_id = neuron_id\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.activation = activation\n",
    "        self.activation_func = ACTIVATIONS.get(activation, relu)\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0, 20)\n",
    "        self.producer = None\n",
    "        self.neuron_acc = None\n",
    "        if self.layer_id == 'layer_0':\n",
    "            self.neuron_acc = -1\n",
    "        elif self.layer_id == 'layer_1':\n",
    "            self.neuron_acc = 128\n",
    "        else:\n",
    "            self.neuron_acc = 10\n",
    "        \n",
    "\n",
    "    def fetch_input(self, image_id):\n",
    "        if self.neuron_acc == -1:\n",
    "            key = f\"streams:{image_id}:initial_data\"\n",
    "            return np.frombuffer(self.redis_handler.get(key), dtype=np.float64)\n",
    "        else:\n",
    "            key = f\"streams:{image_id}:outputs:{self.layer_id_num - 1}\"\n",
    "            return self.redis_handler.get_output_vector(key, self.neuron_acc)\n",
    "\n",
    "    def process_and_send(self, image_id, input_data):\n",
    "        z = np.dot(input_data, self.weights) + self.bias\n",
    "        output = z if self.is_final_layer else self.activation_func(z)\n",
    "        self.redis_handler.hset_expiry(f\"streams:{image_id}:outputs:{self.layer_id_num}\", str(self.neuron_id), output, 60)\n",
    "        msg = f\"{image_id}\"\n",
    "        self.producer.send(msg)\n",
    "\n",
    "    def run(self):\n",
    "        # Instantiate Kafka consumer and producer inside the thread.\n",
    "        consumer = KafkaConsumerHandler(f'layer-{self.layer_id_num}', KAFKA_BROKER, group_id=f\"{self.neuron_id}_{self.layer_id_num}_group\")\n",
    "        self.producer = KafkaProducerHandler(KAFKA_BROKER, f'layer-{self.layer_id_num}-streams')\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                image_id_str = message\n",
    "                image_id = int(image_id_str)\n",
    "                try:\n",
    "                    input_data = self.fetch_input(image_id)\n",
    "                    self.process_and_send(image_id, input_data)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not got_message and (time.time() - last_msg_time > 10):\n",
    "                consumer.commit()\n",
    "                consumer.close()\n",
    "                self.producer.close()\n",
    "                self.redis_handler.close()\n",
    "                break\n",
    "\n",
    "\n",
    "class NeuronOutput(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.redis_handler = RedisHandler('host.docker.internal', 6379, 0, 2)\n",
    "        self.last_layer_id_num = 1\n",
    "        self.neuron_acc = 10\n",
    "\n",
    "    def run(self):\n",
    "        consumer = KafkaConsumerHandler(f'layer-output', KAFKA_BROKER, group_id=f\"neuron_output_coord_group\")\n",
    "        last_msg_time = time.time()\n",
    "        while True:\n",
    "            got_message = False\n",
    "            for message in consumer.consume():\n",
    "                got_message = True\n",
    "                last_msg_time = time.time()\n",
    "                image_id = int(message)\n",
    "                try:\n",
    "                    key = f\"streams:{image_id}:outputs:{self.last_layer_id_num}\"\n",
    "                    outputs = self.redis_handler.get_output_vector(key, self.neuron_acc)\n",
    "                    prediction = int(np.argmax(outputs))\n",
    "                    self.redis_handler.hset('streams:predictions', image_id, prediction)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not got_message and (time.time() - last_msg_time > 15):\n",
    "                consumer.commit()\n",
    "                consumer.close()\n",
    "                self.redis_handler.close()\n",
    "                break\n",
    "\n",
    "# Load network and dataset\n",
    "data = json.load(open(\"node_based_model.json\"))\n",
    "#df = pd.read_csv('data/mnist.csv').head(10)\n",
    "\n",
    "neurons = []\n",
    "\n",
    "for layer_name, layer_info in data.items():\n",
    "    neurons += [Neuron(layer_id=layer_name, neuron_id=i, weights=node['weights'], bias=node['biases'], activation=node['activation'], is_final_layer=(layer_name == list(data.keys())[-1])) for i, node in enumerate(layer_info['nodes'])]\n",
    "\n",
    "neuron_output = NeuronOutput()\n",
    "\n",
    "# Start all threads\n",
    "for thread in neurons:\n",
    "    thread.start()\n",
    "\n",
    "neuron_output.start()\n",
    "\n",
    "print(\"Threads started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0dc27f6-e1c7-4eda-aade-1f8d5210a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads finished\n"
     ]
    }
   ],
   "source": [
    "# Wait for all threads to complete\n",
    "for thread in neurons:\n",
    "    thread.join()\n",
    "\n",
    "neuron_output.join()\n",
    "\n",
    "print(\"Threads finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87a46c34-7f5e-45ec-99c6-f888f877b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.00% (99/100)\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "# Connect to Redis\n",
    "r = RedisHandler('host.docker.internal', 6379, 0)\n",
    "\n",
    "# Get hashes from Redis\n",
    "images_label = r.hgetall('streams:images_label')\n",
    "predictions = r.hgetall('streams:predictions')\n",
    "\n",
    "# Decode bytes to string\n",
    "images_label = {k.decode(): v.decode() for k, v in images_label.items()}\n",
    "predictions = {k.decode(): v.decode() for k, v in predictions.items()}\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = 0\n",
    "total = len(images_label)\n",
    "\n",
    "for field, label_val in images_label.items():\n",
    "    pred_val = predictions.get(field, None)\n",
    "    if pred_val == label_val:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}% ({correct}/{total})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e638ee-a1f1-4c77-9944-6b9b11d9a532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
