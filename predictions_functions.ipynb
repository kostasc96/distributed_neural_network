{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d6ecff-88a2-41d1-9519-e95d0b14b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Output: [0.09341424382860124, 0.10371213700783133, 0.10131805130753267, 0.09368471996196068, 0.09239848420198778, 0.10041246509774145, 0.10744322289471599, 0.09729294397245611, 0.10447055819508498, 0.1058531735320877]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def softmax(outputs):\n",
    "    exp_values = [math.exp(x) for x in outputs]\n",
    "    total = sum(exp_values)\n",
    "    return [x / total for x in exp_values]\n",
    "\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "# Function to apply activation by name\n",
    "def apply_activation(activation, values):\n",
    "    if activation == \"softmax\":\n",
    "        # Apply softmax to the entire list\n",
    "        return softmax(values)\n",
    "    else:\n",
    "        # Apply activation element-wise\n",
    "        activation_fn = {\n",
    "            \"relu\": relu,\n",
    "            \"sigmoid\": sigmoid,\n",
    "            \"tanh\": tanh\n",
    "        }.get(activation, lambda x: x)  # Default to identity function\n",
    "        return [activation_fn(value) for value in values]\n",
    "\n",
    "# Load model data from JSON\n",
    "with open('model.json', 'r') as json_file:\n",
    "    model_data = json.load(json_file)\n",
    "\n",
    "# Neuron function\n",
    "def neuron(weights, bias, inputs):\n",
    "    \"\"\"\n",
    "    Calculate the weighted sum of inputs and bias for a single neuron.\n",
    "    \"\"\"\n",
    "    return sum(w * i for w, i in zip(weights, inputs)) + bias\n",
    "\n",
    "# Forward pass through the network\n",
    "def forward_pass(model_data, inputs):\n",
    "    \"\"\"\n",
    "    Perform a forward pass through the network using the model data from JSON.\n",
    "    \"\"\"\n",
    "    current_inputs = inputs\n",
    "    for layer_name, layer_data in model_data.items():\n",
    "        # Compute outputs for all neurons in the current layer\n",
    "        layer_outputs = [\n",
    "            neuron(weights, bias, current_inputs)\n",
    "            for weights, bias in zip(layer_data[\"weights\"], layer_data[\"biases\"])\n",
    "        ]\n",
    "\n",
    "        # Apply the activation function to the entire layer's output\n",
    "        activation = layer_data[\"activation\"]\n",
    "        current_inputs = apply_activation(activation, layer_outputs)\n",
    "\n",
    "    return current_inputs\n",
    "\n",
    "# Example input data\n",
    "input_data = [0.5, 0.6]  # Adjust based on the input layer size\n",
    "\n",
    "# Perform a forward pass and print the result\n",
    "output = forward_pass(model_data, input_data)\n",
    "print(\"Network Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e41840f-0826-4b07-819f-9ae9230dfb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the network: [0.5, 0.6]\n",
      "Output from layer 0: [0.6699999999999999, 0.99]\n",
      "Output from layer 1: [0.7959221758490919, 0.857294691580815]\n",
      "Predicted class: 1\n",
      "\n",
      "Neuron Relationships:\n",
      "Neuron ID: 0\n",
      "  Weights: [0.1, 0.2]\n",
      "  Bias: 0.5\n",
      "  Activation: relu\n",
      "  Activated by: []\n",
      "  Activates: [2, 3]\n",
      "\n",
      "Neuron ID: 1\n",
      "  Weights: [0.3, 0.4]\n",
      "  Bias: 0.6\n",
      "  Activation: relu\n",
      "  Activated by: []\n",
      "  Activates: [2, 3]\n",
      "\n",
      "Neuron ID: 2\n",
      "  Weights: [0.7, 0.8]\n",
      "  Bias: 0.1\n",
      "  Activation: sigmoid\n",
      "  Activated by: [0, 1]\n",
      "  Activates: []\n",
      "\n",
      "Neuron ID: 3\n",
      "  Weights: [0.9, 1.0]\n",
      "  Bias: 0.2\n",
      "  Activation: sigmoid\n",
      "  Activated by: [0, 1]\n",
      "  Activates: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "# Neuron class: Represents each individual neuron\n",
    "class Neuron:\n",
    "    def __init__(self, neuron_id, weights, bias, activation):\n",
    "        self.neuron_id = neuron_id  # Unique ID for this neuron\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.activated_by = []  # List of neuron IDs that activate this neuron\n",
    "        self.activates = []     # List of neuron IDs that this neuron activates\n",
    "\n",
    "    def activate(self, inputs):\n",
    "        \"\"\"\n",
    "        Activate the neuron based on its inputs, weights, and bias.\n",
    "        Apply the specified activation function to the weighted sum.\n",
    "        \"\"\"\n",
    "        z = sum(w * i for w, i in zip(self.weights, inputs)) + self.bias\n",
    "        return self.apply_activation(z)\n",
    "\n",
    "    def apply_activation(self, z):\n",
    "        \"\"\"\n",
    "        Apply the activation function to the input value (z).\n",
    "        \"\"\"\n",
    "        if self.activation == \"relu\":\n",
    "            return relu(z)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return sigmoid(z)\n",
    "        elif self.activation == \"tanh\":\n",
    "            return tanh(z)\n",
    "        else:\n",
    "            return z  # Identity function if no activation is defined\n",
    "\n",
    "# Layer class: Represents each layer (set of neurons)\n",
    "class Layer:\n",
    "    def __init__(self, neurons):\n",
    "        self.neurons = neurons  # List of neurons in this layer\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform forward propagation through this layer.\n",
    "        \"\"\"\n",
    "        return [neuron.activate(inputs) for neuron in self.neurons]\n",
    "\n",
    "# Build layers from model data and set relationships\n",
    "def build_layer(layer_data, neuron_start_id, previous_layer=None):\n",
    "    \"\"\"\n",
    "    Construct a Layer object from the model data for a specific layer.\n",
    "    Establish relationships (activated_by and activates) between neurons in\n",
    "    the current and previous layers.\n",
    "    \"\"\"\n",
    "    neurons = []\n",
    "    for idx, (weights, bias) in enumerate(zip(layer_data[\"weights\"], layer_data[\"biases\"])):\n",
    "        neuron_id = neuron_start_id + idx\n",
    "        activation = layer_data[\"activation\"]\n",
    "        neuron = Neuron(neuron_id, weights, bias, activation)\n",
    "        neurons.append(neuron)\n",
    "\n",
    "    # If there is a previous layer, establish relationships\n",
    "    if previous_layer:\n",
    "        for prev_neuron in previous_layer.neurons:\n",
    "            for curr_neuron in neurons:\n",
    "                prev_neuron.activates.append(curr_neuron.neuron_id)\n",
    "                curr_neuron.activated_by.append(prev_neuron.neuron_id)\n",
    "\n",
    "    return Layer(neurons), neuron_start_id + len(neurons)\n",
    "\n",
    "# Example model data\n",
    "model_data = {\n",
    "    \"layer_0\": {\n",
    "        \"weights\": [[0.1, 0.2], [0.3, 0.4]],  # 2 neurons with 2 inputs\n",
    "        \"biases\": [0.5, 0.6],\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "    \"layer_1\": {\n",
    "        \"weights\": [[0.7, 0.8], [0.9, 1.0]],  # 2 neurons with 2 inputs\n",
    "        \"biases\": [0.1, 0.2],\n",
    "        \"activation\": \"sigmoid\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build individual layers from model data\n",
    "layers = []\n",
    "neuron_start_id = 0\n",
    "previous_layer = None\n",
    "for layer_name, layer_data in model_data.items():\n",
    "    layer, neuron_start_id = build_layer(layer_data, neuron_start_id, previous_layer)\n",
    "    layers.append(layer)\n",
    "    previous_layer = layer  # Update the previous layer\n",
    "\n",
    "# Define standalone functions for each layer\n",
    "def layer_0(inputs):\n",
    "    return layers[0].forward(inputs)\n",
    "\n",
    "def layer_1(inputs):\n",
    "    return layers[1].forward(inputs)\n",
    "\n",
    "# Perform prediction\n",
    "input_data = [0.5, 0.6]\n",
    "output_layer_0 = layer_0(input_data)\n",
    "output_layer_1 = layer_1(output_layer_0)\n",
    "predicted_class = output_layer_1.index(max(output_layer_1))\n",
    "\n",
    "# Output results\n",
    "print(f\"Input to the network: {input_data}\")\n",
    "print(f\"Output from layer 0: {output_layer_0}\")\n",
    "print(f\"Output from layer 1: {output_layer_1}\")\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Print neuron relationships\n",
    "print(\"\\nNeuron Relationships:\")\n",
    "for layer in layers:\n",
    "    for neuron in layer.neurons:\n",
    "        print(f\"Neuron ID: {neuron.neuron_id}\")\n",
    "        print(f\"  Weights: {neuron.weights}\")\n",
    "        print(f\"  Bias: {neuron.bias}\")\n",
    "        print(f\"  Activation: {neuron.activation}\")\n",
    "        print(f\"  Activated by: {neuron.activated_by}\")\n",
    "        print(f\"  Activates: {neuron.activates}\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
