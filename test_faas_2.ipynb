{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74564db3-3f8a-4030-94bd-300221a807aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial input vector shape: (784,)\n",
      "ERROR: Shape mismatch in Neuron v0_10. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_11. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_12. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_13. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_14. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_15. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_16. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_17. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_18. Weights: (128,), Inputs: (10,)\n",
      "ERROR: Shape mismatch in Neuron v0_19. Weights: (128,), Inputs: (10,)\n",
      "WARNING: The following output neurons were not computed: ['v0_10', 'v0_11', 'v0_12', 'v0_13', 'v0_14', 'v0_15', 'v0_16', 'v0_17', 'v0_18', 'v0_19']\n",
      "Final Output Neurons: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "Predicted Label: 0\n",
      "True Label: 7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from torchvision import datasets\n",
    "\n",
    "# Activation functions\n",
    "activation_functions = {\n",
    "    \"relu\": lambda x: np.maximum(0, x),\n",
    "    \"sigmoid\": expit,\n",
    "    \"tanh\": np.tanh,\n",
    "    \"linear\": lambda x: x,\n",
    "    \"softmax\": lambda x: np.exp(x - np.max(x)) / np.sum(np.exp(x - np.max(x)), keepdims=True)  # Stable softmax\n",
    "}\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"node_based_model.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Store computed neuron outputs\n",
    "outputs = {}\n",
    "layer_outputs = {}  # Store layer-wise outputs to pass as vectors\n",
    "\n",
    "def process_layer(layer_name, input_vector):\n",
    "    \"\"\"\n",
    "    Process an entire layer at once, passing aggregated outputs to the next layer.\n",
    "    \"\"\"\n",
    "    layer = data[layer_name]\n",
    "    next_layer_inputs = {}  # Collect outputs to send to the next layer\n",
    "    \n",
    "    for neuron in layer[\"nodes\"]:\n",
    "        neuron_id = neuron[\"id\"]\n",
    "        weights = np.array(neuron.get(\"weights\", []), dtype=np.float32)\n",
    "        bias = np.array(neuron.get(\"biases\", 0.0), dtype=np.float32)\n",
    "        activation = activation_functions.get(neuron.get(\"activation\", \"linear\"), lambda x: x)\n",
    "        next_nodes = neuron.get(\"next_nodes\", [])\n",
    "        \n",
    "        if weights.shape[0] != input_vector.shape[0]:\n",
    "            print(f\"ERROR: Shape mismatch in Neuron {neuron_id}. Weights: {weights.shape}, Inputs: {input_vector.shape}\")\n",
    "            continue\n",
    "        \n",
    "        output = activation(np.dot(weights, input_vector) + bias)\n",
    "        outputs[neuron_id] = output\n",
    "        \n",
    "        # Collect outputs for the next layer\n",
    "        for next_node in next_nodes:\n",
    "            if next_node not in next_layer_inputs:\n",
    "                next_layer_inputs[next_node] = []\n",
    "            next_layer_inputs[next_node].append(output)\n",
    "    \n",
    "    return next_layer_inputs\n",
    "\n",
    "def forward_pass(input_vector):\n",
    "    \"\"\"Process the entire network from input to output.\"\"\"\n",
    "    outputs.clear()  # Reset outputs for each new forward pass\n",
    "    print(f\"Initial input vector shape: {input_vector.shape}\")\n",
    "    \n",
    "    # Process each layer sequentially\n",
    "    layer_names = list(data.keys())\n",
    "    layer_input = input_vector\n",
    "    \n",
    "    for layer_name in layer_names:\n",
    "        next_layer_inputs = process_layer(layer_name, layer_input)\n",
    "        \n",
    "        if next_layer_inputs:\n",
    "            layer_input = np.array([np.mean(vals) for vals in next_layer_inputs.values()], dtype=np.float32)\n",
    "        else:\n",
    "            break  # Stop if no next layer inputs are found\n",
    "\n",
    "def validate_output_neurons(output_layer_neurons):\n",
    "    \"\"\"Ensure all expected output neurons exist in computed outputs.\"\"\"\n",
    "    missing_neurons = [n for n in output_layer_neurons if n not in outputs]\n",
    "    if missing_neurons:\n",
    "        print(f\"WARNING: The following output neurons were not computed: {missing_neurons}\")\n",
    "    return np.array([outputs.get(neuron_id, 0.0) for neuron_id in output_layer_neurons], dtype=np.float32)\n",
    "\n",
    "# Load MNIST dataset (without PyTorch DataLoader)\n",
    "mnist_dataset = datasets.MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "def preprocess_image(index):\n",
    "    \"\"\"Load and preprocess an MNIST image with the correct normalization\"\"\"\n",
    "    image, label = mnist_dataset[index]\n",
    "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "    image = (image - 0.5) / 0.5  # Normalize to [-1,1]\n",
    "    image = image.flatten()  # Flatten the image to a vector\n",
    "    return image, label\n",
    "\n",
    "# Test the network on an MNIST sample\n",
    "index = 0  # Change this to test different images\n",
    "input_vector, true_label = preprocess_image(index)\n",
    "forward_pass(input_vector)\n",
    "\n",
    "# Identify the output neurons (assuming last layer contains exactly 10 neurons for digits 0-9)\n",
    "output_layer_neurons = [neuron[\"id\"] for neuron in data[list(data.keys())[-1]][\"nodes\"]]\n",
    "output_values = validate_output_neurons(output_layer_neurons)\n",
    "\n",
    "# Apply softmax to output layer if necessary\n",
    "if \"softmax\" in [neuron[\"activation\"] for neuron in data[list(data.keys())[-1]][\"nodes\"]]:\n",
    "    output_values = activation_functions[\"softmax\"](output_values)\n",
    "\n",
    "predicted_label = np.argmax(output_values)  # Find index of max value\n",
    "\n",
    "# Print the output neuron activations and prediction\n",
    "print(\"Final Output Neurons:\", output_values)\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "print(\"True Label:\", true_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aebc20a-b703-42bd-bb11-78a4edda4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 7, Actual label: 7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import expit  # Sigmoid function\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load model from JSON file\n",
    "def load_model(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Define activation functions\n",
    "activation_functions = {\n",
    "    \"relu\": lambda x: np.maximum(0, x),\n",
    "    \"sigmoid\": expit,\n",
    "    \"tanh\": np.tanh,\n",
    "    \"linear\": lambda x: x,\n",
    "    \"softmax\": lambda x: np.exp(x) / np.sum(np.exp(x), axis=0, keepdims=True),\n",
    "}\n",
    "\n",
    "# Neural Network Class - Layer-Based\n",
    "class LayerBasedNN:\n",
    "    def __init__(self, model_json):\n",
    "        self.layers = []\n",
    "        self.activations = []\n",
    "\n",
    "        for layer_key in sorted(model_json.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "            layer = model_json[layer_key]\n",
    "            self.layers.append((np.array(layer[\"weights\"]).T, np.array(layer[\"biases\"])))  # Transpose weights\n",
    "            self.activations.append(activation_functions[layer[\"activation\"]])\n",
    "    \n",
    "    def layer_function(self, x, weights, biases, activation_fn):\n",
    "        \"\"\"Processes a single layer.\"\"\"\n",
    "        return activation_fn(np.dot(x, weights) + biases)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Executes forward pass layer by layer.\"\"\"\n",
    "        for (weights, biases), activation in zip(self.layers, self.activations):\n",
    "            x = self.layer_function(x, weights, biases, activation)\n",
    "        return x\n",
    "\n",
    "# Load model from JSON\n",
    "model_path = \"model.json\"\n",
    "model_json = load_model(model_path)\n",
    "nn = LayerBasedNN(model_json)\n",
    "\n",
    "# Load MNIST data\n",
    "mnist_test = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Test model on an MNIST image\n",
    "image, label = mnist_test[0]\n",
    "image = image.numpy().reshape(-1)  # Flatten image\n",
    "prediction = nn.forward(image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "print(f\"Predicted label: {predicted_label}, Actual label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24fb0e83-653d-42a6-abbd-5ba3d3cbf2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron v0_00: Weighted Sum = -2.4674497316817074, Output = 0.0\n",
      "Neuron v0_01: Weighted Sum = 1.2614272282631034, Output = 1.2614272282631034\n",
      "Neuron v0_02: Weighted Sum = -0.23895092706418275, Output = 0.0\n",
      "Neuron v0_03: Weighted Sum = -1.4914002860764435, Output = 0.0\n",
      "Neuron v0_04: Weighted Sum = 3.117748057827733, Output = 3.117748057827733\n",
      "Neuron v0_05: Weighted Sum = 0.31698690164095567, Output = 0.31698690164095567\n",
      "Neuron v0_06: Weighted Sum = 3.1259155516969326, Output = 3.1259155516969326\n",
      "Neuron v0_07: Weighted Sum = -0.07143255928815356, Output = 0.0\n",
      "Neuron v0_08: Weighted Sum = 2.819468526551663, Output = 2.819468526551663\n",
      "Neuron v0_09: Weighted Sum = 0.22640140615198281, Output = 0.22640140615198281\n",
      "Neuron v0_010: Weighted Sum = -0.008666960421510342, Output = 0.0\n",
      "Neuron v0_011: Weighted Sum = -0.11886079330957217, Output = 0.0\n",
      "Neuron v0_012: Weighted Sum = 2.5216352654524785, Output = 2.5216352654524785\n",
      "Neuron v0_013: Weighted Sum = 0.05993900340864848, Output = 0.05993900340864848\n",
      "Neuron v0_014: Weighted Sum = -0.39452540335832886, Output = 0.0\n",
      "Neuron v0_015: Weighted Sum = 2.5566455572616866, Output = 2.5566455572616866\n",
      "Neuron v0_016: Weighted Sum = 0.08492656298582432, Output = 0.08492656298582432\n",
      "Neuron v0_017: Weighted Sum = -1.3335845013968939, Output = 0.0\n",
      "Neuron v0_018: Weighted Sum = 3.3907507026568546, Output = 3.3907507026568546\n",
      "Neuron v0_019: Weighted Sum = 0.4734404430724781, Output = 0.4734404430724781\n",
      "Neuron v0_020: Weighted Sum = 0.21880844545613332, Output = 0.21880844545613332\n",
      "Neuron v0_021: Weighted Sum = -0.07067899063064545, Output = 0.0\n",
      "Neuron v0_022: Weighted Sum = 3.2074648979151617, Output = 3.2074648979151617\n",
      "Neuron v0_023: Weighted Sum = -2.138655158055585, Output = 0.0\n",
      "Neuron v0_024: Weighted Sum = -1.0577558247290795, Output = 0.0\n",
      "Neuron v0_025: Weighted Sum = -0.045299192892808544, Output = 0.0\n",
      "Neuron v0_026: Weighted Sum = 2.9628431727259223, Output = 2.9628431727259223\n",
      "Neuron v0_027: Weighted Sum = 1.5056974356408297, Output = 1.5056974356408297\n",
      "Neuron v0_028: Weighted Sum = -3.8427713940500072, Output = 0.0\n",
      "Neuron v0_029: Weighted Sum = 0.24201791656155353, Output = 0.24201791656155353\n",
      "Neuron v0_030: Weighted Sum = 3.074418473525826, Output = 3.074418473525826\n",
      "Neuron v0_031: Weighted Sum = 0.13995777973162365, Output = 0.13995777973162365\n",
      "Neuron v0_032: Weighted Sum = 1.493062183330991, Output = 1.493062183330991\n",
      "Neuron v0_033: Weighted Sum = -0.12446620802904823, Output = 0.0\n",
      "Neuron v0_034: Weighted Sum = 0.22280944537935898, Output = 0.22280944537935898\n",
      "Neuron v0_035: Weighted Sum = -0.8917726169948901, Output = 0.0\n",
      "Neuron v0_036: Weighted Sum = 0.39641372458526936, Output = 0.39641372458526936\n",
      "Neuron v0_037: Weighted Sum = -3.3182589926758568, Output = 0.0\n",
      "Neuron v0_038: Weighted Sum = -0.18056567546783386, Output = 0.0\n",
      "Neuron v0_039: Weighted Sum = 1.576160702192465, Output = 1.576160702192465\n",
      "Neuron v0_040: Weighted Sum = -0.07796152905167797, Output = 0.0\n",
      "Neuron v0_041: Weighted Sum = 1.0899567623477537, Output = 1.0899567623477537\n",
      "Neuron v0_042: Weighted Sum = -3.7644254252747396, Output = 0.0\n",
      "Neuron v0_043: Weighted Sum = 0.2975709433863908, Output = 0.2975709433863908\n",
      "Neuron v0_044: Weighted Sum = 0.3002638460195004, Output = 0.3002638460195004\n",
      "Neuron v0_045: Weighted Sum = 0.4137534216088319, Output = 0.4137534216088319\n",
      "Neuron v0_046: Weighted Sum = 0.01482796560754851, Output = 0.01482796560754851\n",
      "Neuron v0_047: Weighted Sum = 0.10437143854208544, Output = 0.10437143854208544\n",
      "Neuron v0_048: Weighted Sum = -2.2223276817860853, Output = 0.0\n",
      "Neuron v0_049: Weighted Sum = 0.19953811310840122, Output = 0.19953811310840122\n",
      "Neuron v0_050: Weighted Sum = 3.2746004681124496, Output = 3.2746004681124496\n",
      "Neuron v0_051: Weighted Sum = 0.8444926075761687, Output = 0.8444926075761687\n",
      "Neuron v0_052: Weighted Sum = 0.4863665215515165, Output = 0.4863665215515165\n",
      "Neuron v0_053: Weighted Sum = 0.3203560033664625, Output = 0.3203560033664625\n",
      "Neuron v0_054: Weighted Sum = -2.5128823281575823, Output = 0.0\n",
      "Neuron v0_055: Weighted Sum = -0.9552451229501584, Output = 0.0\n",
      "Neuron v0_056: Weighted Sum = 0.43054042539618725, Output = 0.43054042539618725\n",
      "Neuron v0_057: Weighted Sum = 0.10560175657853432, Output = 0.10560175657853432\n",
      "Neuron v0_058: Weighted Sum = -2.8714035152395256, Output = 0.0\n",
      "Neuron v0_059: Weighted Sum = 1.4955659053895833, Output = 1.4955659053895833\n",
      "Neuron v0_060: Weighted Sum = 0.34881087125103605, Output = 0.34881087125103605\n",
      "Neuron v0_061: Weighted Sum = -1.1621133822528449, Output = 0.0\n",
      "Neuron v0_062: Weighted Sum = -1.140651754933966, Output = 0.0\n",
      "Neuron v0_063: Weighted Sum = 2.5658547748900356, Output = 2.5658547748900356\n",
      "Neuron v0_064: Weighted Sum = 5.308844057909674, Output = 5.308844057909674\n",
      "Neuron v0_065: Weighted Sum = 3.0913106977596008, Output = 3.0913106977596008\n",
      "Neuron v0_066: Weighted Sum = -4.8393704739697, Output = 0.0\n",
      "Neuron v0_067: Weighted Sum = -1.2781926172816958, Output = 0.0\n",
      "Neuron v0_068: Weighted Sum = -2.377937007786712, Output = 0.0\n",
      "Neuron v0_069: Weighted Sum = -0.0623954768037131, Output = 0.0\n",
      "Neuron v0_070: Weighted Sum = -0.05035330085301362, Output = 0.0\n",
      "Neuron v0_071: Weighted Sum = -0.10125548795245433, Output = 0.0\n",
      "Neuron v0_072: Weighted Sum = 0.06231584735358847, Output = 0.06231584735358847\n",
      "Neuron v0_073: Weighted Sum = -0.13632005127786845, Output = 0.0\n",
      "Neuron v0_074: Weighted Sum = 0.006073924026868498, Output = 0.006073924026868498\n",
      "Neuron v0_075: Weighted Sum = 0.15248531088563044, Output = 0.15248531088563044\n",
      "Neuron v0_076: Weighted Sum = 0.18639648669590594, Output = 0.18639648669590594\n",
      "Neuron v0_077: Weighted Sum = -1.0490730155537689, Output = 0.0\n",
      "Neuron v0_078: Weighted Sum = 2.5207168230196726, Output = 2.5207168230196726\n",
      "Neuron v0_079: Weighted Sum = 3.2620828225971366, Output = 3.2620828225971366\n",
      "Neuron v0_080: Weighted Sum = -1.8134903401692657, Output = 0.0\n",
      "Neuron v0_081: Weighted Sum = -0.03152056238050356, Output = 0.0\n",
      "Neuron v0_082: Weighted Sum = 0.8133936828408534, Output = 0.8133936828408534\n",
      "Neuron v0_083: Weighted Sum = -0.2889180929983046, Output = 0.0\n",
      "Neuron v0_084: Weighted Sum = 0.2771747735191834, Output = 0.2771747735191834\n",
      "Neuron v0_085: Weighted Sum = -0.03526284403887671, Output = 0.0\n",
      "Neuron v0_086: Weighted Sum = 0.37103736987128705, Output = 0.37103736987128705\n",
      "Neuron v0_087: Weighted Sum = -0.3945034554629056, Output = 0.0\n",
      "Neuron v0_088: Weighted Sum = 0.337349761964006, Output = 0.337349761964006\n",
      "Neuron v0_089: Weighted Sum = -0.23886616415855152, Output = 0.0\n",
      "Neuron v0_090: Weighted Sum = 0.49719305143750103, Output = 0.49719305143750103\n",
      "Neuron v0_091: Weighted Sum = 0.21745931620370626, Output = 0.21745931620370626\n",
      "Neuron v0_092: Weighted Sum = 0.2514706804093354, Output = 0.2514706804093354\n",
      "Neuron v0_093: Weighted Sum = 0.11263865512585378, Output = 0.11263865512585378\n",
      "Neuron v0_094: Weighted Sum = 0.037191764352278445, Output = 0.037191764352278445\n",
      "Neuron v0_095: Weighted Sum = 0.024226561849380754, Output = 0.024226561849380754\n",
      "Neuron v0_096: Weighted Sum = -0.09625137910130413, Output = 0.0\n",
      "Neuron v0_097: Weighted Sum = 0.3608248939065551, Output = 0.3608248939065551\n",
      "Neuron v0_098: Weighted Sum = -0.2236977353410531, Output = 0.0\n",
      "Neuron v0_099: Weighted Sum = 0.13972673679071146, Output = 0.13972673679071146\n",
      "Neuron v0_0100: Weighted Sum = -0.09740508989495208, Output = 0.0\n",
      "Neuron v0_0101: Weighted Sum = 2.419148352586519, Output = 2.419148352586519\n",
      "Neuron v0_0102: Weighted Sum = 0.38515464829625806, Output = 0.38515464829625806\n",
      "Neuron v0_0103: Weighted Sum = -2.8177844197736013, Output = 0.0\n",
      "Neuron v0_0104: Weighted Sum = -2.479585928254246, Output = 0.0\n",
      "Neuron v0_0105: Weighted Sum = 0.29966054285554256, Output = 0.29966054285554256\n",
      "Neuron v0_0106: Weighted Sum = 1.3337079620006627, Output = 1.3337079620006627\n",
      "Neuron v0_0107: Weighted Sum = 0.660422257217703, Output = 0.660422257217703\n",
      "Neuron v0_0108: Weighted Sum = 0.13199595819552684, Output = 0.13199595819552684\n",
      "Neuron v0_0109: Weighted Sum = 0.2757932830750806, Output = 0.2757932830750806\n",
      "Neuron v0_0110: Weighted Sum = -1.5986539022070732, Output = 0.0\n",
      "Neuron v0_0111: Weighted Sum = 1.052382763177512, Output = 1.052382763177512\n",
      "Neuron v0_0112: Weighted Sum = 4.296922096602165, Output = 4.296922096602165\n",
      "Neuron v0_0113: Weighted Sum = -0.9955629645233486, Output = 0.0\n",
      "Neuron v0_0114: Weighted Sum = -2.5987577104744073, Output = 0.0\n",
      "Neuron v0_0115: Weighted Sum = 0.42856129988772307, Output = 0.42856129988772307\n",
      "Neuron v0_0116: Weighted Sum = 0.7012447024106035, Output = 0.7012447024106035\n",
      "Neuron v0_0117: Weighted Sum = -0.046506608310384084, Output = 0.0\n",
      "Neuron v0_0118: Weighted Sum = 0.17944498262172628, Output = 0.17944498262172628\n",
      "Neuron v0_0119: Weighted Sum = 2.230843006106143, Output = 2.230843006106143\n",
      "Neuron v0_0120: Weighted Sum = -5.27606097010627, Output = 0.0\n",
      "Neuron v0_0121: Weighted Sum = 0.3545922842935395, Output = 0.3545922842935395\n",
      "Neuron v0_0122: Weighted Sum = 0.2604108788994812, Output = 0.2604108788994812\n",
      "Neuron v0_0123: Weighted Sum = -0.06493602253438463, Output = 0.0\n",
      "Neuron v0_0124: Weighted Sum = 2.6171857528985587, Output = 2.6171857528985587\n",
      "Neuron v0_0125: Weighted Sum = -0.013328578387870077, Output = 0.0\n",
      "Neuron v0_0126: Weighted Sum = -0.030584630165179566, Output = 0.0\n",
      "Neuron v0_0127: Weighted Sum = 0.31975656395872903, Output = 0.31975656395872903\n",
      "Neuron v0_10: Weighted Sum = -3.898949122961867, Output = 1.0\n",
      "Neuron v0_11: Weighted Sum = -4.997197718385556, Output = 1.0\n",
      "Neuron v0_12: Weighted Sum = 1.2150404110559365, Output = 1.0\n",
      "Neuron v0_13: Weighted Sum = 1.8462494026865763, Output = 1.0\n",
      "Neuron v0_14: Weighted Sum = -6.7431895341367305, Output = 1.0\n",
      "Neuron v0_15: Weighted Sum = -2.2373445535806518, Output = 1.0\n",
      "Neuron v0_16: Weighted Sum = -6.318122555934488, Output = 1.0\n",
      "Neuron v0_17: Weighted Sum = 4.755266095186653, Output = 1.0\n",
      "Neuron v0_18: Weighted Sum = -1.5156932349903784, Output = 1.0\n",
      "Neuron v0_19: Weighted Sum = -2.0380052742861907, Output = 1.0\n",
      "Final Output Neurons: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Predicted Label: 0, Actual Label: 7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import expit  # Sigmoid function\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load the JSON model\n",
    "def load_model(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        model = json.load(f)\n",
    "    return model\n",
    "\n",
    "# Define activation functions\n",
    "activation_functions = {\n",
    "    \"relu\": lambda x: np.maximum(0, x),\n",
    "    \"sigmoid\": expit,\n",
    "    \"tanh\": np.tanh,\n",
    "    \"linear\": lambda x: x,\n",
    "    \"softmax\": lambda x: np.exp(x) / np.sum(np.exp(x), axis=0, keepdims=True)  # Softmax for 1D input\n",
    "}\n",
    "\n",
    "# Reverse engineer prev_nodes mapping from next_nodes\n",
    "def build_prev_nodes_mapping(model_json):\n",
    "    prev_nodes_map = {}\n",
    "    for layer in model_json.values():\n",
    "        for neuron in layer[\"nodes\"]:\n",
    "            prev_nodes_map[neuron[\"id\"]] = []\n",
    "    \n",
    "    for layer in model_json.values():\n",
    "        for neuron in layer[\"nodes\"]:\n",
    "            for next_node in neuron[\"next_nodes\"]:\n",
    "                prev_nodes_map[next_node].append(neuron[\"id\"])\n",
    "\n",
    "    return prev_nodes_map\n",
    "\n",
    "# Fire each neuron individually when inputs are ready\n",
    "def process_neuron(neuron, neuron_outputs):\n",
    "    prev_nodes = prev_nodes_map[neuron[\"id\"]]\n",
    "    \n",
    "    # Ensure all previous nodes have fired before calculating this neuron\n",
    "    if not all(node in neuron_outputs for node in prev_nodes):\n",
    "        return None  # Wait until all dependencies are resolved\n",
    "\n",
    "    # Gather inputs from previous neurons\n",
    "    inputs = np.array([neuron_outputs[node] for node in prev_nodes]) if prev_nodes else neuron_outputs[\"input\"]\n",
    "    \n",
    "    weights = np.array(neuron[\"weights\"])\n",
    "    bias = neuron[\"biases\"]\n",
    "    activation = activation_functions[neuron[\"activation\"]]\n",
    "\n",
    "    # Ensure correct input size\n",
    "    if len(inputs) != len(weights):\n",
    "        raise ValueError(f\"Input size mismatch in Neuron {neuron['id']}. Expected {len(weights)} values, got {len(inputs)}\")\n",
    "\n",
    "    weighted_sum = np.dot(inputs, weights) + bias\n",
    "    output = activation(weighted_sum)\n",
    "\n",
    "    print(f\"Neuron {neuron['id']}: Weighted Sum = {weighted_sum}, Output = {output}\")\n",
    "    return output\n",
    "\n",
    "# Process neurons layer by layer, but firing each neuron as soon as its inputs are available\n",
    "def process_layer(layer, neuron_outputs):\n",
    "    remaining_neurons = list(layer[\"nodes\"])\n",
    "\n",
    "    while remaining_neurons:\n",
    "        next_batch = []\n",
    "        for neuron in remaining_neurons:\n",
    "            output = process_neuron(neuron, neuron_outputs)\n",
    "            if output is not None:\n",
    "                neuron_outputs[neuron[\"id\"]] = output\n",
    "            else:\n",
    "                next_batch.append(neuron)  # Keep neurons that still need inputs\n",
    "\n",
    "        if len(next_batch) == len(remaining_neurons):  # No progress -> circular dependency\n",
    "            raise RuntimeError(f\"Circular dependency detected in layer: {layer['id']}\")\n",
    "\n",
    "        remaining_neurons = next_batch  # Update remaining neurons\n",
    "\n",
    "# Load the model from JSON\n",
    "model_path = \"node_based_model.json\"\n",
    "model_json = load_model(model_path)\n",
    "\n",
    "# Build the prev_nodes mapping\n",
    "prev_nodes_map = build_prev_nodes_mapping(model_json)\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist_test = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Test on a single image\n",
    "image, label = mnist_test[0]\n",
    "image = image.numpy().reshape(-1)  # Flatten 28x28 image into a vector\n",
    "\n",
    "# Initialize neuron outputs\n",
    "neuron_outputs = {\"input\": image}\n",
    "\n",
    "# Process layers sequentially, ensuring neurons fire when ready\n",
    "for layer_key in sorted(model_json.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "    layer = model_json[layer_key]\n",
    "    process_layer(layer, neuron_outputs)\n",
    "\n",
    "# Extract final output neurons\n",
    "final_outputs = np.array([neuron_outputs[node[\"id\"]] for node in model_json[layer_key][\"nodes\"]])\n",
    "predicted_label = np.argmax(final_outputs)\n",
    "\n",
    "print(f\"Final Output Neurons: {final_outputs}\")\n",
    "print(f\"Predicted Label: {predicted_label}, Actual Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbfe2b-cf23-44dd-85a8-4d11e91fd397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
